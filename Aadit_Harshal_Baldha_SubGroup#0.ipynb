{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0b91b1",
   "metadata": {},
   "source": [
    "# Name: Aadit Harshal Baldha\n",
    "# Batch: Fall 2024 (2nd Sem)\n",
    "# CWID: 20029691"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8bb98",
   "metadata": {},
   "source": [
    "## Topic: ML: Fundamentals and Applications Project Individual Work for Cluster Group #0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366ab70",
   "metadata": {},
   "source": [
    "### 3.3 Building the Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ff7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "clustered_df = pd.read_csv('output/clustered_data.csv')\n",
    "\n",
    "# Step 1: Prepare data\n",
    "X = clustered_df.drop(columns=['Cluster'])\n",
    "y = clustered_df['Cluster']\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 3: Define the model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(y.unique()),\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Set up Grid Search Parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Step 5: Cross-Validation Strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 6: Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "classification_model_best_params = grid_search.best_params_\n",
    "print(\"Best Parameters Found:\", grid_search.best_params_)\n",
    "\n",
    "# Step 8: Predict\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - XGBoost Prediction with GridSearchCV')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf459834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = clustered_df[clustered_df['Cluster']==0].drop(columns=['Bankrupt?'])  # Replace 'Bankrupt?' with your target column\n",
    "y = clustered_df[clustered_df['Cluster']==0]['Bankrupt?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE  # Importing SMOTE for oversampling\n",
    "\n",
    "# Define your X and y\n",
    "# X = <your feature matrix>\n",
    "# y = <your target labels>\n",
    "\n",
    "# Train-test split (Important to have a separate holdout set later)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation strategy (Stratified ensures balanced class proportions across folds)\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 1: Define base models and their grids, including class_weight for imbalance handling\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced', None]  # Handling class imbalance\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 7],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 7, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'class_weight': ['balanced', None]  # Handling class imbalance\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'scale_pos_weight': [1, 2, 3]  # Helps in handling imbalanced classes in XGBoost\n",
    "}\n",
    "\n",
    "# Step 2: Initialize models\n",
    "models = {\n",
    "    'dt': (DecisionTreeClassifier(random_state=42), param_grid_dt),\n",
    "    'knn': (make_pipeline(StandardScaler(), KNeighborsClassifier()), param_grid_knn),\n",
    "    'rf': (RandomForestClassifier(random_state=42), param_grid_rf),\n",
    "    'xgb': (XGBClassifier(\n",
    "        use_label_encoder=False, \n",
    "        eval_metric='logloss', \n",
    "        random_state=42\n",
    "    ), param_grid_xgb)\n",
    "}\n",
    "\n",
    "# Step 3: Grid Search for each base model, including class weight adjustments\n",
    "best_estimators = {}\n",
    "\n",
    "for name, (model, param_grid) in models.items():\n",
    "    print(f\"Tuning {name.upper()}...\")\n",
    "    gs = GridSearchCV(model, param_grid, cv=cv_strategy, n_jobs=-1, scoring='accuracy')\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_estimators[name] = gs.best_estimator_\n",
    "    print(f\"Best params for {name.upper()}: {gs.best_params_}\")\n",
    "    print(f\"Best CV Accuracy: {gs.best_score_:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Step 4: Apply SMOTE for oversampling the minority class in the training set\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Build the Stacking Classifier\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=[(name, model) for name, model in best_estimators.items()],\n",
    "    final_estimator=LogisticRegression(class_weight='balanced'),  # Handling imbalance in the final model\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# Step 6: Train Stacking Classifier with resampled data\n",
    "stack_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 7: Evaluate\n",
    "y_pred = stack_model.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report for Stacked Model:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Stacked Model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff7b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LogisticRegression(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a826f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a65202",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "y_pred = cross_val_predict(stack_model, X, y, cv=cv, method='predict')\n",
    "\n",
    "acc = accuracy_score(y, y_pred)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7256a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AaHB_CS556B_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
