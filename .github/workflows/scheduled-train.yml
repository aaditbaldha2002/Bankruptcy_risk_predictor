name: Scheduled Model Training

on:
  schedule:
    - cron: '0 6 * * *'  # Every day at 6:00 UTC
  workflow_dispatch:

jobs:
  train:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
      AWS_DEFAULT_REGION: 'us-east-1'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install dvc[s3]  # Ensures S3 support

      - name: Configure DVC remote
        run: |
          dvc remote modify s3remote access_key_id $AWS_ACCESS_KEY_ID
          dvc remote modify s3remote secret_access_key $AWS_SECRET_ACCESS_KEY
          dvc remote modify s3remote region $AWS_DEFAULT_REGION
          dvc remote default s3remote  # Make it the default

      - name: Pull DVC data/artifacts
        run: |
          dvc pull --verbose
          chmod -R a+rw artifacts/

      - name: Initialize ZenML repo and import stack
        run: |
          zenml init
          zenml stack delete bankruptcy_risk_stack || true
          zenml stack import bankruptcy_risk_stack.yaml

      - name: Set ZenML stack
        run: |
          zenml stack set bankruptcy_risk_stack

      - name: Run ZenML pipeline
        run: python run_deploy_pipeline.py
      
      - name: Tracking artifacts using DVC 
        run: dvc add artifacts/
             git add artifacts.dvc
             git commit -m "tracking artifacts using dvc"
      - name: Pushing artifacts to S3 remote bucket
        run:  git push
              dvc push
      
      - name: Pushing artifacts mapping to S3 remote bucket
        run: python src/create_artifacts_mapping.py
